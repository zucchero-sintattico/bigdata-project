{
 "cells": [
  {
   "cell_type": "code",
   "id": "990d985c-c9e8-49c0-abbe-789ed7fe90cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T14:18:27.785922Z",
     "start_time": "2025-01-23T14:18:27.177176Z"
    }
   },
   "source": "import org.apache.spark",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "val sc = spark.SparkContext.getOrCreate()",
   "id": "916fb4cdbe9e6b4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T14:36:38.973911Z",
     "start_time": "2025-01-23T14:36:38.774309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val path_to_datasets = \"../../../datasets/processed\"\n",
    "\n",
    "val path_to_tracks = path_to_datasets + \"/tracks.csv\"\n",
    "val path_to_playlists = path_to_datasets + \"/playlists.csv\"\n",
    "val path_to_track_in_playlists = path_to_datasets + \"/tracks_in_playlist.csv\"\n",
    "val path_to_artists = path_to_datasets + \"/artists.csv\""
   ],
   "id": "c6ecb118412e0c11",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_to_datasets: String = ../../../datasets/processed\n",
       "path_to_tracks: String = ../../../datasets/processed/tracks.csv\n",
       "path_to_playlists: String = ../../../datasets/processed/playlists.csv\n",
       "path_to_track_in_playlists: String = ../../../datasets/processed/tracks_in_playlist.csv\n",
       "path_to_artists: String = ../../../datasets/processed/artists.csv\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T14:55:39.236243Z",
     "start_time": "2025-01-23T14:55:38.608769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "object CsvParser {\n",
    "\n",
    "  val noGenresListed = \"(no genres listed)\"\n",
    "  val commaRegex = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val pipeRegex = \"\\\\|(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val quotes = \"\\\"\"\n",
    "\n",
    "  //  case class PlayList(PID: String, playlist_name: String, num_followers: Int)\n",
    "  //\n",
    "  //  case class Track(track_uri: String, track_name: String, duration_ms: Int, artist_uri: String, album_uri: String, album_name: String)\n",
    "  //\n",
    "  //  case class Artist(artist_uri: String, artist_name: String)\n",
    "  //\n",
    "  //  case class TrackInPlaylist(PID: String, track_uri: String, pos: Int)\n",
    "\n",
    "  //  // (PID, playlist_name, num_followers)\n",
    "  //  def parsePlayListLine(line: String): Option[PlayList] = {\n",
    "  //    try {\n",
    "  //      val input = line.split(commaRegex)\n",
    "  //      Some(PlayList(input(0).trim, input(1).trim, input(2).trim.toInt))\n",
    "  //    } catch {\n",
    "  //      case _: Exception => None\n",
    "  //    }\n",
    "  //  }\n",
    "  //\n",
    "  //  // (track_uri, track_name, duration_ms, artist_uri, album_uri, album_name)\n",
    "  //  def parseTrackLine(line: String): Option[Track] = {\n",
    "  //    try {\n",
    "  //      val input = line.split(commaRegex)\n",
    "  //      Some(Track(input(0).trim, input(1).trim, input(2).trim.toInt, input(3).trim, input(4).trim, input(5).trim))\n",
    "  //    } catch {\n",
    "  //      case _: Exception => None\n",
    "  //    }\n",
    "  //  }\n",
    "  //\n",
    "  //  // (artist_uri, artist_name)\n",
    "  //  def parseArtistLine(line: String): Option[Artist] = {\n",
    "  //    try {\n",
    "  //      val input = line.split(commaRegex)\n",
    "  //      Some(Artist(input(0).trim, input(1).trim))\n",
    "  //    } catch {\n",
    "  //      case _: Exception => None\n",
    "  //    }\n",
    "  //  }\n",
    "  //\n",
    "  //  // (PID, track_uri, pos)\n",
    "  //  def parseTrackInPlaylistLine(line: String): Option[TrackInPlaylist] = {\n",
    "  //    try {\n",
    "  //      val input = line.split(commaRegex)\n",
    "  //      Some(TrackInPlaylist(input(0).trim, input(1).trim, input(2).trim.toInt))\n",
    "  //    } catch {\n",
    "  //      case _: Exception => None\n",
    "  //    }\n",
    "  //  }\n",
    "  // (PID, playlist_name, num_followers)\n",
    "  def parsePlayListLine(line: String): Option[(String, String, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      if (input(0).trim == \"7000\") {\n",
    "        println(\"PLAYLIST: \" + input.mkString(\", \"))\n",
    "      }\n",
    "      Some(input(0).trim, input(1).trim, input(2).trim.toInt)\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // (track_uri, track_name, duration_ms, artist_uri, album_uri, album_name)\n",
    "  def parseTrackLine(line: String): Option[(String, String, Int, String, String, String)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim, input(1).trim, input(2).trim.toInt, input(3).trim, input(4).trim, input(5).trim)\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // (artist_uri, artist_name)\n",
    "  def parseArtistLine(line: String): Option[(String, String)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim, input(1).trim)\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // (PID, track_uri, pos)\n",
    "  def parseTrackInPlaylistLine(line: String): Option[(String, String, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "\n",
    "      Some(input(0).trim, input(1).trim, input(2).trim.toInt)\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "}"
   ],
   "id": "3b926bf2bd3efb08",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object CsvParser\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:07:04.845805Z",
     "start_time": "2025-01-23T15:07:03.406543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val rddTracks = sc.textFile(path_to_tracks).\n",
    "  flatMap(CsvParser.parseTrackLine)\n",
    "\n",
    "val rddPlaylists = sc.textFile(path_to_playlists).\n",
    "  flatMap(CsvParser.parsePlayListLine)\n",
    "\n",
    "val rddTrackInPlaylists = sc.textFile(path_to_track_in_playlists).\n",
    "  flatMap(CsvParser.parseTrackInPlaylistLine)\n",
    "\n",
    "val rddArtists = sc.textFile(path_to_artists).\n",
    "  flatMap(CsvParser.parseArtistLine)"
   ],
   "id": "212e24357ce478d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddTracks: org.apache.spark.rdd.RDD[(String, String, Int, String, String, String)] = MapPartitionsRDD[827] at flatMap at <console>:33\n",
       "rddPlaylists: org.apache.spark.rdd.RDD[(String, String, Int)] = MapPartitionsRDD[830] at flatMap at <console>:36\n",
       "rddTrackInPlaylists: org.apache.spark.rdd.RDD[(String, String, Int)] = MapPartitionsRDD[833] at flatMap at <console>:39\n",
       "rddArtists: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[836] at flatMap at <console>:42\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:07:12.120190Z",
     "start_time": "2025-01-23T15:07:05.099651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// Join all the RDDs\n",
    "val rddPlaylistTracksInPlaylist = rddPlaylists.keyBy(_._1)\n",
    "    .join(rddTrackInPlaylists.keyBy(_._1))\n",
    "    .map({\n",
    "      case (pid, (playlist, tip)) => (pid, tip._2)\n",
    "    })\n",
    "println(\"AfterJoin: \" + rddPlaylistTracksInPlaylist.distinct().count())\n",
    "println(\"Default: \" + rddTrackInPlaylists.distinct().count())\n",
    "\n",
    "// now take PID from both rdd and check if there are PID in trackInPlaylist that are not in playlist\n",
    "val pid_tip = rddTrackInPlaylists.map(x => x._1)\n",
    "val pid_playlist = rddPlaylists.map(x => x._1)\n",
    "val diff = pid_tip.distinct().subtract(pid_playlist)\n",
    "println(\"Diff: \" + diff.collect().mkString(\", \"))\n",
    "println(\"Diff count: \" + diff.count())\n",
    "\n",
    "val rddPlaylistTracksInPlaylistTracks = rddPlaylistTracksInPlaylist.keyBy({\n",
    "    case (_, t_uri) => t_uri\n",
    "  })\n",
    "  .join(rddTracks.keyBy(\n",
    "    {\n",
    "      case (t_uri, _, _, _, _, _) => t_uri\n",
    "    }\n",
    "  ))\n",
    "  // take all fields of the track, and the playlist PID\n",
    "  .map(x => (x._2._1._1, x._2._2._2, x._2._2._3, x._2._2._4, x._2._2._5, x._2._2._6))\n",
    "val rddPlaylistTracksInPlaylistTracksArtists = rddPlaylistTracksInPlaylistTracks.keyBy(_._4)\n",
    "  .join(rddArtists.keyBy(_._1))\n",
    "  // keep all the fields of the track, and the playlist PID and the artist name\n",
    "  .map(x => (x._2._1._1, x._2._1._2, x._2._1._3, x._2._1._4, x._2._1._5, x._2._1._6, x._2._2._2))\n",
    "\n"
   ],
   "id": "3aae4ea7aaf6997a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAYLIST: 7000, NewNew, 2\n",
      "AfterJoin: 658644\n",
      "Default: 667516\n",
      "PLAYLIST: 7000, NewNew, 2\n",
      "Diff: \n",
      "Diff count: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rddPlaylistTracksInPlaylist: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[842] at map at <console>:38\n",
       "pid_tip: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[849] at map at <console>:45\n",
       "pid_playlist: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[850] at map at <console>:46\n",
       "diff: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[857] at subtract at <console>:47\n",
       "rddPlaylistTracksInPlaylistTracks: org.apache.spark.rdd.RDD[(String, String, Int, String, String, String)] = MapPartitionsRDD[863] at map at <console>:60\n",
       "rddPlaylistTracksInPlaylistTracksArtists: org.apache.spark.rdd.RDD[(String, String, Int, String, String, String, String)] = MapPartitionsRDD[869] at map at <console>:64\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:58:28.181250Z",
     "start_time": "2025-01-23T13:57:57.897913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// (PID, track_name, duration_ms, artist_uri, album_uri, album_name, artist_name)\n",
    "val pidArtistTrack = rddPlaylistTracksInPlaylistTracksArtists.map(x => ((x._1, x._4), 1))\n",
    "val artistTrackCount = pidArtistTrack\n",
    "  .reduceByKey(_ + _)\n",
    "\n",
    "val pidToArtistTracks = artistTrackCount.map(x => (x._1._1, x._2))\n",
    "// (PID, num_tracks)\n",
    "val averageSongsPerArtist = pidToArtistTracks\n",
    "  .groupByKey() // Raggruppa tutte le playlist\n",
    "  .mapValues { counts =>\n",
    "    val totalArtists = counts.size\n",
    "    val totalTracks = counts.sum\n",
    "    totalTracks.toDouble / totalArtists\n",
    "  }\n",
    "\n",
    "//averageSongsPerArtist.collect().foreach { case x =>\n",
    "// println(s\"Playlist ${x._1} ha una media di ${x._2} canzoni per artista.\")\n",
    "//}\n",
    "\n",
    "val totalPlaylists = averageSongsPerArtist.count() // Numero totale di playlist\n",
    "val sumOfAverages = averageSongsPerArtist.map(_._2).sum() // Somma di tutte le medie\n",
    "\n",
    "val overallAverage = sumOfAverages / totalPlaylists // Media complessiva\n",
    "\n",
    "// Mostra il risultato\n",
    "println(s\"La media complessiva di canzoni per artista è: $overallAverage\")\n",
    "\n",
    "\n"
   ],
   "id": "11aca052489d192b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La media complessiva di canzoni per artista è: 2.165874500096723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pidArtistTrack: org.apache.spark.rdd.RDD[((String, String), Int)] = MapPartitionsRDD[174] at map at <console>:33\n",
       "artistTrackCount: org.apache.spark.rdd.RDD[((String, String), Int)] = ShuffledRDD[175] at reduceByKey at <console>:35\n",
       "pidToArtistTracks: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[176] at map at <console>:37\n",
       "averageSongsPerArtist: org.apache.spark.rdd.RDD[(String, Double)] = MapPartitionsRDD[178] at mapValues at <console>:41\n",
       "totalPlaylists: Long = 98856\n",
       "sumOfAverages: Double = 214109.68958156166\n",
       "overallAverage: Double = 2.165874500096723\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55523541f9c3b4fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
